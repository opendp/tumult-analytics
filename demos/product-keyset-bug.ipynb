{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c53125-e8ef-4355-aa0b-840cdc161da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from tmlt.analytics.session import Session\n",
    "from tmlt.analytics.keyset import KeySet\n",
    "from tmlt.analytics.query_builder import QueryBuilder\n",
    "from tmlt.analytics.privacy_budget import ApproxDPBudget, PureDPBudget\n",
    "from tmlt.analytics.protected_change import AddOneRow\n",
    "import random\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import rand, floor, col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73873cdb-aaab-4c7a-88c7-f59040325474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/04 11:48:46 WARN Utils: Your hostname, Bayards-Macbook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.153 instead (on interface en0)\n",
      "25/10/04 11:48:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/04 11:48:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.Builder().getOrCreate()\n",
    "\n",
    "df = (\n",
    "    spark.range(1_000_000)\n",
    "    .withColumn(\"A\", (floor(rand() * 5_000) + 1).cast(\"int\"))\n",
    "    .withColumn(\"B\", (floor(rand() * 100) + 1).cast(\"int\"))\n",
    "    .withColumn(\"C\", (floor(rand() * 10) + 1).cast(\"int\"))\n",
    "    .withColumn(\"D\", (floor(rand() * 10) + 1).cast(\"int\"))\n",
    "    .drop(\"id\")  # drop the default range column\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1832a230-9f32-43f7-8262-ca44aa098471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlescarlson/Documents/open_source_projects/tumult-analytics/.venv/lib/python3.9/site-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "25/10/04 11:49:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Approx DP Bug\n",
    "\n",
    "approx_sess = Session.from_dataframe(\n",
    "    privacy_budget=ApproxDPBudget(float(\"inf\"),1),\n",
    "    source_id=\"simpledata\",\n",
    "    dataframe=df,\n",
    "    protected_change=AddOneRow(),\n",
    ")\n",
    "\n",
    "keyset_query = QueryBuilder(\"simpledata\").get_groups([\"A\", \"B\"])\n",
    "groups = approx_sess.evaluate(keyset_query, ApproxDPBudget(5, 1e-6))\n",
    "\n",
    "keyset = KeySet.from_dataframe(groups) * KeySet.from_dict({\"C\":range(1,11)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2d5f80-099a-42f5-85d0-c694a3313ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:===================================================>     (9 + 1) / 10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-----+\n",
      "|  A|  B|  C|count|\n",
      "+---+---+---+-----+\n",
      "|  1|  6|  8|    0|\n",
      "|  1| 11|  7|    1|\n",
      "|  1| 15|  3|    0|\n",
      "|  1| 31|  5|    1|\n",
      "|  1| 31|  8|   -1|\n",
      "|  1| 36|  2|    3|\n",
      "|  1| 36| 10|   -1|\n",
      "|  1| 38|  2|    1|\n",
      "|  1| 38|  9|    2|\n",
      "|  1| 51|  2|   -3|\n",
      "|  1| 59|  6|   -1|\n",
      "|  1| 59|  9|   -1|\n",
      "|  1| 92|  6|    1|\n",
      "|  1| 99|  3|   -1|\n",
      "|  1| 99|  7|   -1|\n",
      "|  1| 99|  8|    0|\n",
      "|  2|  3|  6|    0|\n",
      "|  2|  8|  2|   -2|\n",
      "|  2|  8|  9|    1|\n",
      "|  2| 13|  6|    0|\n",
      "+---+---+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Query Execution \n",
    "query=QueryBuilder(\"simpledata\").groupby(keyset).count()\n",
    "result = approx_sess.evaluate(query, ApproxDPBudget(1, 0.1))\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86e9eae-af85-49a1-b47e-f575aa829e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyset = KeySet.from_dataframe(df.select([\"A\"]).distinct())*(KeySet.from_dataframe(df.select([\"B\"]).distinct())*KeySet.from_dict({\"C\":range(1,11)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec8c20c9-83fc-4d29-81c9-456adbd675b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/04 11:49:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/10/04 11:49:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/10/04 11:49:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/10/04 11:49:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/10/04 11:49:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/10/04 11:49:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/10/04 11:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/10/04 11:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/10/04 11:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/10/04 11:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-----+\n",
      "|  A|  B|  C|count|\n",
      "+---+---+---+-----+\n",
      "|  1|  2|  9|    2|\n",
      "|  1|  3|  7|    0|\n",
      "|  1|  4|  3|    1|\n",
      "|  1|  4|  8|   -1|\n",
      "|  1|  4|  9|    0|\n",
      "|  1|  5|  2|   -2|\n",
      "|  1|  7|  7|    2|\n",
      "|  1| 10|  1|    1|\n",
      "|  1| 11|  6|   -2|\n",
      "|  1| 11|  9|    2|\n",
      "|  1| 15|  8|   -1|\n",
      "|  1| 15| 10|   -2|\n",
      "|  1| 18|  4|    1|\n",
      "|  1| 19|  2|    0|\n",
      "|  1| 19|  6|    0|\n",
      "|  1| 19| 10|    0|\n",
      "|  1| 20|  6|    0|\n",
      "|  1| 20|  7|    0|\n",
      "|  1| 21|  8|    0|\n",
      "|  1| 23|  5|    1|\n",
      "+---+---+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/04 11:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Query Execution \n",
    "query=QueryBuilder(\"simpledata\").groupby(keyset).count()\n",
    "result = approx_sess.evaluate(query, PureDPBudget(1))\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4186719c-5343-4074-a116-bc5f069cd54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a34bf0-8809-4a9e-a4f0-a29c41479568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  A|  B|\n",
      "+---+---+\n",
      "|  1| 56|\n",
      "|  1| 64|\n",
      "|  1| 80|\n",
      "|  1|132|\n",
      "|  1|175|\n",
      "|  1|180|\n",
      "|  1|255|\n",
      "|  1|269|\n",
      "|  1|271|\n",
      "|  1|352|\n",
      "|  1|365|\n",
      "|  1|442|\n",
      "|  1|622|\n",
      "|  1|685|\n",
      "|  1|772|\n",
      "|  1|780|\n",
      "|  1|845|\n",
      "|  1|878|\n",
      "|  1|881|\n",
      "|  1|953|\n",
      "+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groups.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093ad0d-160a-4be7-b295-fd6ea9799bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
